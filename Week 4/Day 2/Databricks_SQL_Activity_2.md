# Databricks Activity: Exploring the `bakehouse` Schema

This activity will help you get comfortable using Databricks SQL and Notebooks to explore a normalized sample dataset of a fictional bakery business. The dataset is found in the **`samples.bakehouse`** schema.

---

## Part 1: SQL Editor Queries (Run in SQL Workspace)

Make sure you're in the **SQL workspace**, connected to a running **SQL Warehouse**.

### Task 1.1: Preview the `sales_transactions` table

### Task 1.2: Count total sales records

### Task 1.3: Get top 5 products by quantity sold

### Task 1.4: Join transactions with customers and show customer name with transactions


### Task 1.5: Total sales per franchise


---

## Part 2: Working in a Notebook (Run with `%sql` or Python)

Open a new **notebook** and attach it to an **interactive cluster** (not SQL Warehouse). You’ll be using both `%sql` cells and Python.


### Task 2.1: Run a `%sql` cell to list all customers


### Task 2.2: Run a Python cell to load and display the `products` table


### Task 2.3: Show sales summary using SQL inside the notebook (sales by customer)


### Task 2.4: Load multiple tables and join in Python



### Task 2.5: Optional Challenge — Write Your Own Query

Use either SQL or Python to:
- Find the average sale amount per store
- Or identify customers who made more than 5 purchases

---

## Wrap-Up

By completing this activity, you practiced:
- Exploring sample data in Databricks SQL
- Joining tables
- Using both SQL and PySpark
- Working with real-world structured data
